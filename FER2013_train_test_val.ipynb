{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER2013_train_test_val.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNED/uBffTE/UE2O7vnf09",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmswl0707/light_weighted_CNN_for_FER/blob/main/FER2013_train_test_val.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1oEw2td5cJD"
      },
      "source": [
        "import cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\r\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\r\n",
        "from torchsummary import summary\r\n",
        "from torch import optim\r\n",
        "import copy\r\n",
        "import time\r\n",
        "import torch\r\n",
        "from torch.utils import data\r\n",
        "from torch import nn\r\n",
        "\r\n",
        "from torchvision.transforms import ToTensor\r\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loE18RKl-asw"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "train_dir = '/content/drive/My Drive/Colab Notebooks/FER2013/train/'\r\n",
        "test_dir = '/content/drive/My Drive/Colab Notebooks/FER2013/test/'\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSnlNeLQlVDY"
      },
      "source": [
        "### Data augmentation\r\n",
        "\r\n",
        "transforms = transforms.Compose([transforms.Resize((48,48)),\r\n",
        "                                 transforms.Grayscale(),\r\n",
        "                                 transforms.RandomRotation(degrees=30),\r\n",
        "                                 transforms.RandomHorizontalFlip(),\r\n",
        "                                 transforms.ToTensor()\r\n",
        "                                 ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQB4tyfkXm3"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\r\n",
        "print(train_on_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJLtuDl4rMII"
      },
      "source": [
        "### 데이터 불러오기\r\n",
        "\r\n",
        "df_train = ImageFolder(root= train_dir, transform = transforms)\r\n",
        "df_test = ImageFolder(root = test_dir, transform = transforms)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skm_wiA_Pn6j"
      },
      "source": [
        "# test 갯수와 카테고리 확인\r\n",
        "\r\n",
        "categories = list(df_test.class_to_idx.keys())\r\n",
        "print(categories)\r\n",
        "num_classes = len(categories)\r\n",
        "\r\n",
        "print(len(df_test))\r\n",
        "#print(len(num_classes))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfimrS6urM_L"
      },
      "source": [
        "#### train / test 데이터 데이터 구성확인\r\n",
        "\r\n",
        "def get_count(path,set_):\r\n",
        "    \r\n",
        "    dict_ = {}\r\n",
        "    \r\n",
        "    for exp in os.listdir(path):\r\n",
        "        dir_ = path + exp\r\n",
        "        dict_[exp] = len(os.listdir(dir_))\r\n",
        "        \r\n",
        "    df = pd.DataFrame(dict_,index=[set_])\r\n",
        "    return df\r\n",
        "    \r\n",
        "\r\n",
        "train_count = get_count(train_dir,'train')\r\n",
        "test_count = get_count(test_dir,'test')\r\n",
        "\r\n",
        "print(train_count)\r\n",
        "print(test_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcWvy0NHrUr4"
      },
      "source": [
        "#train, test set의 class 분포 확인\r\n",
        "'''\r\n",
        "emotions = {0 : 'angry', 1: 'disgust', 2 : 'fear', 3 : 'happy', 4 : 'sad', 5 : 'surprise', 6: 'neutral'}\r\n",
        "\r\n",
        "em_count = df_train['emotion'].value_counts().plot(kind='bar')\r\n",
        "plt.xlabel(\"total\", labelpad=14)\r\n",
        "plt.ylabel(\"emotions\", labelpad=14)\r\n",
        "plt.title(\"value_counts by emotions_[train]\", y=1.02);\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1BxVgavqFaq"
      },
      "source": [
        "### train /val split\r\n",
        "\r\n",
        "val_size = 0.25 # train set의 0.2 사이즈 만큼\r\n",
        "\r\n",
        "num_data = len(df_train)\r\n",
        "indices = list(range(num_data))\r\n",
        "np.random.shuffle(indices)\r\n",
        "\r\n",
        "\r\n",
        "val_split = int(np.floor(val_size * num_data))\r\n",
        "val_idx, train_idx = indices[:val_split], indices[val_split:]\r\n",
        "\r\n",
        "\r\n",
        "print(len(train_idx), len(val_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaej8U9wGwUg"
      },
      "source": [
        "\r\n",
        "###데이터 로더\r\n",
        "\r\n",
        "dataset_sizes = {\r\n",
        "    'train' : len(train_idx),\r\n",
        "    'test' : len(df_test),\r\n",
        "    'val' : len(val_idx)\r\n",
        "}\r\n",
        "\r\n",
        "train_sampler = SubsetRandomSampler(train_idx)\r\n",
        "val_sampler = SubsetRandomSampler(val_idx)\r\n",
        "test_sampler = SubsetRandomSampler(df_test)\r\n",
        "\r\n",
        "batch_size=16\r\n",
        "\r\n",
        "loaders = {\r\n",
        "    'train': torch.utils.data.DataLoader(df_train, batch_size=16, sampler=train_sampler),\r\n",
        "    'val': torch.utils.data.DataLoader(df_train, batch_size=16, sampler=val_sampler),\r\n",
        "}\r\n",
        "test_loader = torch.utils.data.DataLoader(df_test, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXr_8VTtr4Li"
      },
      "source": [
        "## 데이터 확인하기\r\n",
        "\r\n",
        "def imshow(img):\r\n",
        "    img = (img+1)/2    \r\n",
        "    img = img.squeeze()\r\n",
        "    np_img = np.asarray(img)\r\n",
        "    plt.imshow(np_img)\r\n",
        "\r\n",
        "\r\n",
        "dataiter = iter(loaders['val'])\r\n",
        "images, labels = dataiter.next()\r\n",
        "print(images.shape,labels.shape)\r\n",
        "images = images.numpy() \r\n",
        "fig = plt.figure(figsize=(25, 10))\r\n",
        "\r\n",
        "for idx in np.arange(8):\r\n",
        "    ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\r\n",
        "    imshow(images[idx])\r\n",
        "    ax.set_title(categories[int(labels[idx])],fontsize=20,color='white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn2NtBO0sAj7"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.nn.utils.prune as prune\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class SeparableConv2d(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\r\n",
        "        super(SeparableConv2d, self).__init__()\r\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels,\r\n",
        "                                   bias=bias)\r\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.depthwise(x)\r\n",
        "        x = self.pointwise(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class ResidualBlock(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_channeld, out_channels):\r\n",
        "        super(ResidualBlock, self).__init__()\r\n",
        "\r\n",
        "        self.residual_conv = nn.Conv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=1, stride=2,\r\n",
        "                                       bias=False)\r\n",
        "        self.residual_bn = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "\r\n",
        "        self.sepConv1 = SeparableConv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=3, bias=False,\r\n",
        "                                        padding=1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.elu = nn.ELU()\r\n",
        "\r\n",
        "        self.sepConv2 = SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, bias=False,\r\n",
        "                                        padding=1)\r\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        res = self.residual_conv(x)\r\n",
        "        res = self.residual_bn(res)\r\n",
        "        x = self.sepConv1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.elu(x)\r\n",
        "        x = self.sepConv2(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.maxp(x)\r\n",
        "        return res + x\r\n",
        "\r\n",
        "\r\n",
        "class Block(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_channeld, out_channels):\r\n",
        "        super(Block, self).__init__()\r\n",
        "\r\n",
        "        self.sep1 = SeparableConv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=3, bias=False, padding=1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.elu1 = nn.ELU()\r\n",
        "        self.sep2 = SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, bias=False, padding=1)\r\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.elu2 = nn.ELU()\r\n",
        "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.sep1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.elu1(x)\r\n",
        "\r\n",
        "        x = self.sep2(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.elu2(x)\r\n",
        "        x = self.maxp(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class SELayer(nn.Module):\r\n",
        "    def __init__(self, in_channeld, reduction=16):\r\n",
        "        super(SELayer, self).__init__()\r\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\r\n",
        "        self.fc = nn.Sequential(\r\n",
        "            nn.Linear(in_channeld, in_channeld // reduction, bias=False),\r\n",
        "            nn.ReLU6(inplace=True),\r\n",
        "            nn.Linear(in_channeld // reduction, in_channeld, bias=False),\r\n",
        "            nn.Sigmoid()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        b, c, _, _ = x.size()\r\n",
        "        y = self.avg_pool(x).view(b, c)\r\n",
        "        y = self.fc(y).view(b, c, 1, 1)\r\n",
        "        return x * y.expand_as(x)\r\n",
        "\r\n",
        "\r\n",
        "class SEBasicBlock(nn.Module):\r\n",
        "    expansion = 1\r\n",
        "\r\n",
        "    def __init__(self, in_channeld, out_channels, stride=1, downsample=None, groups=1,\r\n",
        "                 base_width=64, dilation=1, norm_layer=None,\r\n",
        "                 *, reduction=16):\r\n",
        "        super(SEBasicBlock, self).__init__()\r\n",
        "        self.Conv1 = nn.Conv2d(in_channeld, out_channels, stride)\r\n",
        "        self.bn1 = nn.BatchNorm2d(in_channeld)\r\n",
        "        self.relu = nn.ReLU6(inplace=True)\r\n",
        "\r\n",
        "        self.Conv2 = nn.Conv2d(in_channeld, out_channels, 1)\r\n",
        "        self.bn2 = nn.BatchNorm2d(in_channeld)\r\n",
        "        self.se = SELayer(in_channeld, reduction)\r\n",
        "        self.downsample = downsample\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        residual = x\r\n",
        "        out = self.Conv1(x)\r\n",
        "        out = self.bn1(out)\r\n",
        "        out = self.relu(out)\r\n",
        "        out = self.Conv2(out)\r\n",
        "        out = self.bn2(out)\r\n",
        "        out = self.se(out)\r\n",
        "\r\n",
        "        if self.downsample is not None:\r\n",
        "            residual = self.downsample(x)\r\n",
        "\r\n",
        "        out += residual\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "class Model(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, num_classes):\r\n",
        "        super(Model, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, dilation=2, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(8, affine=True, momentum=0.99, eps=1e-3)\r\n",
        "        self.relu1 = nn.ELU()\r\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, dilation=2, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(8, momentum=0.99, eps=1e-3)\r\n",
        "        self.relu2 = nn.ELU()\r\n",
        "\r\n",
        "\r\n",
        "        self.module1 = ResidualBlock(in_channeld=8, out_channels=16)\r\n",
        "        self.module2 = SEBasicBlock(16, 16, stride=1, downsample=None, groups=1,\r\n",
        "                                    base_width=64, dilation=1, norm_layer=None, reduction=16)\r\n",
        "        self.module3 = Block(in_channeld=16, out_channels=32)\r\n",
        "        self.module4 = ResidualBlock(in_channeld=32, out_channels=64)\r\n",
        "        self.module5 = SEBasicBlock(64, 64, stride=1, downsample=None, groups=1,\r\n",
        "                                    base_width=64, dilation=1, norm_layer=None, reduction=16)\r\n",
        "        self.module6 = Block(in_channeld=64, out_channels=128)\r\n",
        "\r\n",
        "\r\n",
        "        self.last_conv = nn.Conv2d(in_channels=128, out_channels=num_classes, kernel_size=3, padding=1, stride=2)\r\n",
        "        self.avgp = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        x = input\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.relu1(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.relu2(x)\r\n",
        "        x = self.module1(x)\r\n",
        "        x = self.module2(x)\r\n",
        "        x = self.module3(x)\r\n",
        "        x = self.module4(x)\r\n",
        "        x = self.module5(x)\r\n",
        "        x = self.module6(x)\r\n",
        "        x = self.last_conv(x)\r\n",
        "        x = self.avgp(x)\r\n",
        "        x = x.view((x.shape[0], -1))\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcFvjI8EWPs_"
      },
      "source": [
        "def graph_loss(train_loss, val_loss):\r\n",
        "    fig,ax = plt.subplots(1,1,figsize=(5,5))\r\n",
        "    ax.plot(train_loss)\r\n",
        "    ax.plot(val_loss)\r\n",
        "    ax.legend(['Train Loss','val Loss'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBhtaAj069rX"
      },
      "source": [
        "class EarlyStopping:\r\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\r\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\r\n",
        "                            Default: 7\r\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\r\n",
        "                            Default: False\r\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\r\n",
        "                            Default: 0\r\n",
        "            path (str): checkpoint저장 경로\r\n",
        "                            Default: 'checkpoint.pt'\r\n",
        "        \"\"\"\r\n",
        "        self.patience = patience\r\n",
        "        self.verbose = verbose\r\n",
        "        self.counter = 0\r\n",
        "        self.best_score = None\r\n",
        "        self.early_stop = False\r\n",
        "        self.val_loss_min = np.Inf\r\n",
        "        self.delta = delta\r\n",
        "        self.path = path\r\n",
        "\r\n",
        "    def __call__(self, val_loss, model):\r\n",
        "\r\n",
        "        score = -val_loss\r\n",
        "\r\n",
        "        if self.best_score is None:\r\n",
        "            self.best_score = score\r\n",
        "            self.save_checkpoint(val_loss, model)\r\n",
        "        elif score < self.best_score + self.delta:\r\n",
        "            self.counter += 1\r\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\r\n",
        "            if self.counter >= self.patience:\r\n",
        "                self.early_stop = True\r\n",
        "        else:\r\n",
        "            self.best_score = score\r\n",
        "            self.save_checkpoint(val_loss, model)\r\n",
        "            self.counter = 0\r\n",
        "\r\n",
        "    def save_checkpoint(self, val_loss, model):\r\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\r\n",
        "        if self.verbose:\r\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\r\n",
        "        torch.save(model.state_dict(), self.path)\r\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSP0HJwbW3bD"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "writer = SummaryWriter()\r\n",
        "patience = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMp2nBFUU9zI"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs):\r\n",
        "    train_losses, val_losses = [], []\r\n",
        "    avg_train_losses, avg_val_losses = [], []\r\n",
        "\r\n",
        "    since = time.time()\r\n",
        "\r\n",
        "    early_stopping = EarlyStopping(patience = patience, verbose = True)\r\n",
        "\r\n",
        "    for epoch in range(1, num_epochs +1) :\r\n",
        "            #print('Epoch {}/{}'.format(epoch + 1, num_epochs))\r\n",
        "            #print('-' * 10)\r\n",
        "        for phase in ['train', 'val']:\r\n",
        "            if phase == 'train':\r\n",
        "            # Each epoch has a training and validation phase\r\n",
        "        \r\n",
        "                model.train()  # Set model to training mode\r\n",
        "\r\n",
        "                #running_loss = 0.0\r\n",
        "                #corrects = 0\r\n",
        "\r\n",
        "                # Iterate over data.\r\n",
        "                for batch, (inputs, labels) in enumerate(loaders['train'], 1):\r\n",
        "                    inputs = inputs.to(device)\r\n",
        "                    labels = labels.to(device)\r\n",
        "\r\n",
        "                    # zero the parameter gradients\r\n",
        "                    optimizer.zero_grad()\r\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\r\n",
        "                        outputs = model(inputs)\r\n",
        "                        #_, preds = torch.max(outputs, 1)\r\n",
        "                        loss = criterion(outputs, labels)\r\n",
        "                        loss.backward()\r\n",
        "                        optimizer.step()\r\n",
        "\r\n",
        "                     # statistics\r\n",
        "                    train_losses.append(loss.item())\r\n",
        "\r\n",
        "                    #corrects += torch.sum(preds == labels.data)\r\n",
        "\r\n",
        "                #scheduler.step()\r\n",
        "\r\n",
        "                #epoch_loss = running_loss / dataset_sizes[phase]\r\n",
        "                #epoch_acc = corrects.double() / dataset_sizes[phase]\r\n",
        "\r\n",
        "                \r\n",
        "                #train_loss.append(epoch_loss)\r\n",
        "                #print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, train_losses, epoch_acc))\r\n",
        "\r\n",
        "\r\n",
        "            if phase == 'val':\r\n",
        "                model.eval()\r\n",
        "                \r\n",
        "                with torch.no_grad():\r\n",
        "                    #val_loss = 0.0\r\n",
        "                    #val_corrects = 0\r\n",
        "                    \r\n",
        "                    for batch, (inputs, labels) in enumerate(loaders['val']):\r\n",
        "                        inputs = inputs.to(device)\r\n",
        "                        labels = labels.to(device)\r\n",
        "                          \r\n",
        "                        #forward\r\n",
        "                        outputs = model(inputs)\r\n",
        "\r\n",
        "                        #_, preds = torch.max(outputs, 1)\r\n",
        "                        val_loss = criterion(outputs, labels)\r\n",
        "                        val_losses.append(val_loss.item())\r\n",
        "                        #val_corrects += torch.sum(preds == labels.data)\r\n",
        "\r\n",
        "                    #val_acc = val_corrects.double() / dataset_sizes[phase]    \r\n",
        "                    #print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, val_losses, val_acc))\r\n",
        "                 \r\n",
        "\r\n",
        "                    train_loss = np.average(train_losses)\r\n",
        "                    val_loss = np.average(val_losses)\r\n",
        "                    avg_train_losses.append(train_loss)\r\n",
        "                    avg_val_losses.append(val_loss)\r\n",
        "\r\n",
        "                    epoch_len = len(str(num_epochs))\r\n",
        "\r\n",
        "\r\n",
        "                    print_msg = (f'[{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}] ' +\r\n",
        "                                f'train_loss: {train_loss:.4f} ' +\r\n",
        "                                f'valid_loss: {val_loss:.4f}')\r\n",
        "\r\n",
        "                    print(print_msg)\r\n",
        "\r\n",
        "            # deep copy the model\r\n",
        "            #if phase == 'val' and epoch_acc > best_acc:\r\n",
        "                #best_acc = epoch_acc\r\n",
        "                    train_losses = []\r\n",
        "                    val_losses = []\r\n",
        "\r\n",
        "                    early_stopping(val_loss, model)\r\n",
        "                    if early_stopping.early_stop:\r\n",
        "                        print(\"Early stopping\")\r\n",
        "                        break\r\n",
        "\r\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\r\n",
        "\r\n",
        "    return model_ft, avg_train_losses, avg_val_losses\r\n",
        "\r\n",
        "                #best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    time_elapsed = time.time() - since\r\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\r\n",
        "        time_elapsed // 60, time_elapsed % 60))\r\n",
        "    #print('Best val Acc: {:4f}'.format(best_acc))\r\n",
        "\r\n",
        "    graph_loss(train_losses, val_losses)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0MW5d-Y7NiE"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOs9qnaX7PkA"
      },
      "source": [
        "model_ft = Model(num_classes=7)\r\n",
        "model_ft = model_ft.to(device)\r\n",
        "print(summary(model_ft,(1,50,50)))\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(model_ft.parameters(), momentum=0.9,lr=0.02, weight_decay=5e-3)\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmjOhBUg7SmT"
      },
      "source": [
        "model, train_loss, val_loss = train_model(model_ft, criterion, optimizer, exp_lr_scheduler, num_epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCgMuqG87W2d"
      },
      "source": [
        "# 훈련이 진행되는 과정에 따라 loss를 시각화\r\n",
        "fig = plt.figure(figsize=(10,8))\r\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\r\n",
        "plt.plot(range(1,len(val_loss)+1),val_loss,label='Validation Loss')\r\n",
        "\r\n",
        "# validation loss의 최저값 지점을 찾기\r\n",
        "minposs = val_loss.index(min(val_loss))+1\r\n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\r\n",
        "\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.ylim(0, 0.5) # 일정한 scale\r\n",
        "plt.xlim(0, len(train_loss)+1) # 일정한 scale\r\n",
        "plt.grid(True)\r\n",
        "plt.legend()\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()\r\n",
        "fig.savefig('loss_plot.png', bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFvHdBho7a-k"
      },
      "source": [
        "class_correct = list(0. for i in range(7))\r\n",
        "class_total = list(0. for i in range(7))\r\n",
        "\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    for data in loaders['test']:\r\n",
        "        images, labels = data\r\n",
        "        images, labels = images.to(device), labels.to(device)\r\n",
        "        outputs = model(images)\r\n",
        "        _, predicted = torch.max(outputs, 1)\r\n",
        "        c = (predicted == labels).squeeze()  #예측과 실제 라벨 비교\r\n",
        "                \r\n",
        "        for i in range(labels.shape[0]):\r\n",
        "            label = labels[i]\r\n",
        "            class_correct[label] += c[i].item()\r\n",
        "            class_total[label] += 1\r\n",
        "            \r\n",
        "            total += labels.size(0)\r\n",
        "            correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "print('Accuracy of the network on test images: %d %%' % (\r\n",
        "    100 * correct / total))            \r\n",
        "            \r\n",
        "for i in range(7):\r\n",
        "    print('Accuracy of %5s : %2d %%' % (\r\n",
        "        categories[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G22ZoKLVs-A"
      },
      "source": [
        "def visualize_model(model, num_images=6):\r\n",
        "    was_training = model.training\r\n",
        "    model.eval()\r\n",
        "    images_so_far = 0\r\n",
        "    fig = plt.figure()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\r\n",
        "            inputs = inputs.to(device)\r\n",
        "            labels = labels.to(device)\r\n",
        "\r\n",
        "            outputs = model(inputs)\r\n",
        "            _, preds = torch.max(outputs, 1)\r\n",
        "            fig = plt.figure(figsize=(25, 16))\r\n",
        "\r\n",
        "            for j in range(inputs.size()[0]):\r\n",
        "                images_so_far += 1\r\n",
        "                ax = fig.add_subplot(2, num_images//2, images_so_far)\r\n",
        "                ax.axis('off')\r\n",
        "                ax.set_title('predicted: {}'.format(class_labels[preds[j]]))\r\n",
        "                imshow(inputs.cpu().data[j])\r\n",
        "\r\n",
        "                if images_so_far == num_images:\r\n",
        "                    model.train(mode=was_training)\r\n",
        "                    return\r\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i9-nt5eWlgp"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPFw_8GnWn5g"
      },
      "source": [
        "model_ft = Model(num_classes=7)\r\n",
        "model_ft = model_ft.to(device)\r\n",
        "print(summary(model_ft,(1,44,44)))\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), momentum=0.9,lr=0.02, weight_decay=5e-3)\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYEIZ7rtWob9"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}