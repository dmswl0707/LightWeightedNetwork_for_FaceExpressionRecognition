{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ckplus_train_ex.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPLlZJ8lGKbR4+odxFPcGy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmswl0707/light_weighted_CNN_for_FER/blob/main/ckplus_train_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti7X1rbexQ8g"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import copy\r\n",
        "import time\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import optim\r\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\r\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\r\n",
        "from torchvision.datasets import ImageFolder\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "from torchsummary import summary\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "import shutil\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNWAFoutvyFj"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "print(train_on_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48SWyfldxYhq"
      },
      "source": [
        "\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive/')\r\n",
        "df_dir='/content/drive/My drive/Colab Notebooks/CK+48'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1fhiCTAxdYO"
      },
      "source": [
        "transform_train=transforms.Compose([transforms.Resize((50,50)),\r\n",
        "                                    transforms.Grayscale(),\r\n",
        "                                    transforms.RandomRotation(degrees=30),\r\n",
        "                                    transforms.RandomHorizontalFlip(),\r\n",
        "                                    transforms.ToTensor(),\r\n",
        "                                    transforms.Normalize((0.5),(0.5))\r\n",
        "                                    ])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOGwchJlxeuP"
      },
      "source": [
        "dataset = ImageFolder(root='/content/drive/My Drive/Colab Notebooks/CK+48/train', transform=transform_train)\r\n",
        "\r\n",
        "\r\n",
        "categories = list(train_dataset.class_to_idx.keys())\r\n",
        "print(categories)\r\n",
        "num_classes = len(categories)\r\n",
        "\r\n",
        "print(len(train_dataset))\r\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fDsDsb64Zyl"
      },
      "source": [
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "image_w=50\r\n",
        "image_h=50\r\n",
        "\r\n",
        "test_size = 0.2\r\n",
        "num_train = len(dataset)\r\n",
        "indices = list(range(num_train))\r\n",
        "np.random.shuffle(indices)\r\n",
        "test_split = int(np.floor(test_size * num_train))\r\n",
        "test_idx, train_idx = indices[:test_split], indices[test_split:]\r\n",
        "\r\n",
        "print(len(test_idx), len(train_idx))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# define samplers for obtaining training and validation batche\r\n",
        "train_sampler = SubsetRandomSampler(train_idx)\r\n",
        "test_sampler = SubsetRandomSampler(test_idx)\r\n",
        "\r\n",
        "\r\n",
        "dataset_sizes = {\r\n",
        "    'train' : len(train_idx),\r\n",
        "    'test' : len(test_idx)\r\n",
        "}\r\n",
        "\r\n",
        "loaders = {\r\n",
        "    'train': torch.utils.data.DataLoader(dataset, batch_size=16, sampler=train_sampler),\r\n",
        "    'test': torch.utils.data.DataLoader(dataset, batch_size=16, sampler=test_sampler)\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def imshow(img):\r\n",
        "    img = (img+1)/2    \r\n",
        "    img = img.squeeze()\r\n",
        "    np_img = np.asarray(img)\r\n",
        "    plt.imshow(np_img)\r\n",
        "    #plt.show()\r\n",
        "\r\n",
        "\r\n",
        "dataiter = iter(loaders['train'])\r\n",
        "images, labels = dataiter.next()\r\n",
        "print(images.shape,labels.shape)\r\n",
        "images = images.numpy() \r\n",
        "fig = plt.figure(figsize=(25, 10))\r\n",
        "\r\n",
        "for idx in np.arange(8):\r\n",
        "    ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\r\n",
        "    imshow(images[idx])\r\n",
        "    ax.set_title(categories[int(labels[idx])],fontsize=20,color='white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkngjVpkxwBP"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.nn.utils.prune as prune\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class SeparableConv2d(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\r\n",
        "        super(SeparableConv2d, self).__init__()\r\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels,\r\n",
        "                                   bias=bias)\r\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.depthwise(x)\r\n",
        "        x = self.pointwise(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class ResidualBlock(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_channeld, out_channels):\r\n",
        "        super(ResidualBlock, self).__init__()\r\n",
        "\r\n",
        "        self.residual_conv = nn.Conv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=1, stride=2,\r\n",
        "                                       bias=False, dilation=2)\r\n",
        "        self.residual_bn = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "\r\n",
        "        self.sepConv1 = SeparableConv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=3, bias=False,\r\n",
        "                                        padding=1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.elu = nn.ELU()\r\n",
        "\r\n",
        "        self.sepConv2 = SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, bias=False,\r\n",
        "                                        padding=1)\r\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        res = self.residual_conv(x)\r\n",
        "        res = self.residual_bn(res)\r\n",
        "        x = self.sepConv1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.elu(x)\r\n",
        "        x = self.sepConv2(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.maxp(x)\r\n",
        "        return res + x\r\n",
        "\r\n",
        "\r\n",
        "class Block(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_channeld, out_channels):\r\n",
        "        super(Block, self).__init__()\r\n",
        "\r\n",
        "        self.sep1 = SeparableConv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=3, bias=False, padding=1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.elu1 = nn.ELU()\r\n",
        "        self.sep2 = SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, bias=False, padding=1)\r\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\r\n",
        "        self.elu2 = nn.ELU()\r\n",
        "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.sep1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.elu1(x)\r\n",
        "        x = self.sep2(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.elu2(x)\r\n",
        "        x = self.maxp(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class SELayer(nn.Module):\r\n",
        "    def __init__(self, in_channeld, reduction=16):\r\n",
        "        super(SELayer, self).__init__()\r\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\r\n",
        "        self.fc = nn.Sequential(\r\n",
        "            nn.Linear(in_channeld, in_channeld // reduction, bias=False),\r\n",
        "            nn.ReLU6(inplace=True),\r\n",
        "            nn.Linear(in_channeld // reduction, in_channeld, bias=False),\r\n",
        "            nn.Sigmoid()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        b, c, _, _ = x.size()\r\n",
        "        y = self.avg_pool(x).view(b, c)\r\n",
        "        y = self.fc(y).view(b, c, 1, 1)\r\n",
        "        return x * y.expand_as(x)\r\n",
        "\r\n",
        "\r\n",
        "class SEBasicBlock(nn.Module):\r\n",
        "    expansion = 1\r\n",
        "\r\n",
        "    def __init__(self, in_channeld, out_channels, stride=1, downsample=None, groups=1,\r\n",
        "                 base_width=64, dilation=1, norm_layer=None,\r\n",
        "                 *, reduction=16):\r\n",
        "        super(SEBasicBlock, self).__init__()\r\n",
        "        self.Conv1 = nn.Conv2d(in_channeld, out_channels, stride, dilation=2)\r\n",
        "        self.bn1 = nn.BatchNorm2d(in_channeld)\r\n",
        "        self.relu = nn.ReLU6(inplace=True)\r\n",
        "        self.Conv2 = nn.Conv2d(in_channeld, out_channels, 1, dilation=2)\r\n",
        "        self.bn2 = nn.BatchNorm2d(in_channeld)\r\n",
        "        self.se = SELayer(in_channeld, reduction)\r\n",
        "        self.downsample = downsample\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        residual = x\r\n",
        "        out = self.Conv1(x)\r\n",
        "        out = self.bn1(out)\r\n",
        "        out = self.relu(out)\r\n",
        "        out = self.Conv2(out)\r\n",
        "        out = self.bn2(out)\r\n",
        "        out = self.se(out)\r\n",
        "\r\n",
        "        if self.downsample is not None:\r\n",
        "            residual = self.downsample(x)\r\n",
        "\r\n",
        "        out += residual\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "class Model(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, num_classes):\r\n",
        "        super(Model, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(8, affine=True, momentum=0.99, eps=1e-3)\r\n",
        "        self.relu1 = nn.ELU()\r\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(8, momentum=0.99, eps=1e-3)\r\n",
        "        self.relu2 = nn.ELU()\r\n",
        "\r\n",
        "\r\n",
        "        self.module1 = ResidualBlock(in_channeld=8, out_channels=16)\r\n",
        "        self.module2 = SEBasicBlock(16, 16, stride=1, downsample=None, groups=1,\r\n",
        "                                    base_width=64, dilation=1, norm_layer=None, reduction=16)\r\n",
        "        self.module3 = Block(in_channeld=16, out_channels=32)\r\n",
        "        self.module4 = ResidualBlock(in_channeld=32, out_channels=64)\r\n",
        "        self.module5 = SEBasicBlock(64, 64, stride=1, downsample=None, groups=1,\r\n",
        "                                    base_width=64, dilation=1, norm_layer=None, reduction=16)\r\n",
        "        self.module6 = Block(in_channeld=64, out_channels=128)\r\n",
        "\r\n",
        "\r\n",
        "        self.last_conv = nn.Conv2d(in_channels=128, out_channels=num_classes, kernel_size=3, padding=1, stride=2)\r\n",
        "        self.avgp = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        x = input\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.relu1(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.bn2(x)\r\n",
        "        x = self.relu2(x)\r\n",
        "        x = self.module1(x)\r\n",
        "        x = self.module2(x)\r\n",
        "        x = self.module3(x)\r\n",
        "        x = self.module4(x)\r\n",
        "        x = self.module5(x)\r\n",
        "        x = self.module6(x)\r\n",
        "        x = self.last_conv(x)\r\n",
        "        x = self.avgp(x)\r\n",
        "        x = x.view((x.shape[0], -1))\r\n",
        "        return x\r\n",
        "\r\n",
        "def graph_loss(train_loss,test_loss):\r\n",
        "    fig,ax = plt.subplots(1,1,figsize=(5,5))\r\n",
        "    ax.plot(train_loss)\r\n",
        "    ax.plot(test_loss)\r\n",
        "    ax.legend(['Train Loss','Test Loss'])\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QVwoc9EuQrR"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEHSb5HQx7g8"
      },
      "source": [
        "\r\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\r\n",
        "    train_loss, test_loss = [], []\r\n",
        "    since = time.time()\r\n",
        "\r\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "    best_acc = 0.0\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\r\n",
        "        print('-' * 10)\r\n",
        "\r\n",
        "        # Each epoch has a training and validation phase\r\n",
        "        for phase in ['train', 'test']:\r\n",
        "            if phase == 'train':\r\n",
        "                model.train()  # Set model to training mode\r\n",
        "            if phase == 'test':\r\n",
        "                model.eval()  # Set model to evaluate mode\r\n",
        "\r\n",
        "            running_loss = 0.0\r\n",
        "            running_corrects = 0\r\n",
        "\r\n",
        "            # Iterate over data.\r\n",
        "            for inputs, labels in loaders[phase]:\r\n",
        "                inputs = inputs.to(device)\r\n",
        "                labels = labels.to(device)\r\n",
        "\r\n",
        "                # zero the parameter gradients\r\n",
        "                optimizer.zero_grad()\r\n",
        "\r\n",
        "                # forward\r\n",
        "                # track history if only in train\r\n",
        "                with torch.set_grad_enabled(phase == 'train'):\r\n",
        "                    outputs = model(inputs)\r\n",
        "                    _, preds = torch.max(outputs, 1)\r\n",
        "                    loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "                    # backward + optimize only if in training phase\r\n",
        "                    if phase == 'train':\r\n",
        "                        loss.backward()\r\n",
        "                        optimizer.step()\r\n",
        "\r\n",
        "                # statistics\r\n",
        "                running_loss += loss.item() * inputs.size(0)\r\n",
        "                running_corrects += torch.sum(preds == labels.data)\r\n",
        "\r\n",
        "            if phase == 'train':\r\n",
        "                scheduler.step()\r\n",
        "\r\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\r\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\r\n",
        "\r\n",
        "            if phase == 'train':\r\n",
        "                train_loss.append(epoch_loss)\r\n",
        "                writer.add_scalar(\"Acc/train\", epoch_acc, epoch)\r\n",
        "                writer.add_scalar(\"loss/train\", epoch_loss, epoch)\r\n",
        "\r\n",
        "            if phase == 'test' :\r\n",
        "                test_loss.append(epoch_loss)\r\n",
        "                writer.add_scalar(\"Acc/test\", epoch_acc, epoch)\r\n",
        "                writer.add_scalar(\"loss/test\", epoch_loss, epoch)\r\n",
        "\r\n",
        "\r\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\r\n",
        "                phase, epoch_loss, epoch_acc))\r\n",
        "\r\n",
        "\r\n",
        "            # deep copy the model\r\n",
        "            if phase == 'test' and epoch_acc > best_acc:\r\n",
        "                best_acc = epoch_acc\r\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        print()\r\n",
        "\r\n",
        "    time_elapsed = time.time() - since\r\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\r\n",
        "        time_elapsed // 60, time_elapsed % 60))\r\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\r\n",
        "\r\n",
        "    #graph_loss(train_loss, test_loss)\r\n",
        "\r\n",
        "\r\n",
        "    # load best model weights\r\n",
        "    model.load_state_dict(best_model_wts)\r\n",
        "    return model\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htn1xRYRyBQq"
      },
      "source": [
        "def visualize_model(model, num_images=6):\r\n",
        "    was_training = model.training\r\n",
        "    model.eval()\r\n",
        "    images_so_far = 0\r\n",
        "    fig = plt.figure()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for i, (inputs, labels) in enumerate(loaders['test']):\r\n",
        "            inputs = inputs.to(device)\r\n",
        "            labels = labels.to(device)\r\n",
        "\r\n",
        "            outputs = model(inputs)\r\n",
        "            _, preds = torch.max(outputs, 1)\r\n",
        "            fig = plt.figure(figsize=(25, 16))\r\n",
        "\r\n",
        "            for j in range(inputs.size()[0]):\r\n",
        "                images_so_far += 1\r\n",
        "                ax = fig.add_subplot(2, num_images//2, images_so_far)\r\n",
        "                ax.axis('off')\r\n",
        "                ax.set_title('predicted: {}'.format(class_labels[preds[j]]))\r\n",
        "                imshow(inputs.cpu().data[j])\r\n",
        "\r\n",
        "                if images_so_far == num_images:\r\n",
        "                    model.train(mode=was_training)\r\n",
        "                    return\r\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhOV90WmyD4o"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNsUcXqryF24"
      },
      "source": [
        "model_ft = Model(num_classes=7)\r\n",
        "model_ft = model_ft.to(device)\r\n",
        "print(summary(model_ft,(1,50,50)))\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), momentum=0.9,lr=0.02, weight_decay=5e-3)\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc9beItFyJK8"
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0EqobNdyLZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}